Настройка окружения

Исследовательская работа проводилась в ОС Windows 10, использовалась среда для научных исследований Anaconda, Python3. Дополнительно установил пакет pymorphy2 для POS-тегирования токенов из датасетов на русском языке, для английского датасета (CoNLL2003) использовались предоставленные организаторами теги (chunk и POS). Для удобной работы с датасетами они были приведены к модифицированному формату датасетов CoNLL (были добавлены столбцы OFFSET и LEN - отступ токена и его длина), в коде они хранятся в виде модифицированных NLTK Corpus-ов. (код обработки можно найти в файлах .ipynb, а код NLTK Corpus-а - в файле corpus.py)

Пространство признаков

В первоначальной итерации было решено рассмотреть следующие признаки:
1) Часть речи (POS-tag)
1.1) Для CoNLL2003 датасета - и chunk-tag
2) Капитализация (normal, Proper, CAPITAL, cAmEl-case)
3) IsNumber
4) IsPunctuator
5) Начальная форма слова
6) Само слово

Для обработки датасетов и генерации признаков был написан отдельный класс Generator (файл generator.py), который на основании входных данных создает матрицу признаков, эта матрица обрабатывается OneHotEncoder-ом из пакета sklearn, опционально сохраняется в файл и возвращается в вызывающий код. Матрица признаков получается очень разреженной, поскольку ее размер напрямую зависит от размера словаря датасета.
Далее матрица признаков используется для обучения классификатора LogisticRegression из пакета sklearn (обучение на 3000 - 4000 токенах), который показал результаты в 55 - 60 (F-мера). 