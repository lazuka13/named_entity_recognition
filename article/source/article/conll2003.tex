\section{CoNLL 2003}

CoNLL 2003 (Conference on Computational Natural Language Learning) - конференция по машинной обработке естественного языка, прошедшая в Канаде в 2003 году. Общей задачей конференции было решение проблемы NER, Распознавания Именованных Сущностей, для двух языков - немецкого и английского. Для измерения точности использовались метрики точности (precision), полноты (recall) и F-мера (F-measure), участие приняли 16 различных систем, наилучшим результом стали 88.76 для английского и 72.41 для немецкого от системы FIJZ03 (здесь и в дальнейшем результаты указаны по метрике F1, если не указано обратное, кроме того, данные результаты вычислялись путем усреднения качества по всем типам сущностей). Ниже в таблицах 1 и 2 приведем также качество в разбивку по точности/полноте/F-мере (5 наилучших результатов для каждого языка):

\begin{table}[ht]
\caption{Первый датасет}
\centering
\label{first_dataset}
\begin{tabular}{|l|l|l|l|}
\hline
English      & Precision & Recall  & F-measure \\ \hline
FIJZ03       & 88.99\%   & 88.54\% & 88.76${\pm}$0.7 \\ \hline
CN03         & 88.12\%   & 88.51\% & 88.31${\pm}$0.7 \\ \hline
KSNM03       & 85.93\%   & 86.21\% & 86.07${\pm}$0.8 \\ \hline
ZJ03         & 86.13\%   & 84.88\% & 85.50${\pm}$0.9 \\ \hline
CMP03b       & 84.05\%   & 85.96\% & 85.00${\pm}$0.8 \\ \hline
baseline     & 71.91\%   & 50.90\% & 59.61${\pm}$1.2 \\ \hline
\end{tabular}
\end{table}

\begin{table}[ht]
\caption{Второй датасет}
\centering
\label{second_dataset}
\begin{tabular}{|l|l|l|l|}
\hline
German      & Precision & Recall  & F-measure \\ \hline
FIJZ03      & 83.87\%   & 63.71\% & 72.41${\pm}$1.3 \\ \hline
KSNM03      & 80.38\%   & 65.04\% & 71.90${\pm}$1.2 \\ \hline
ZJ03        & 82.00\%   & 63.03\% & 71.27${\pm}$1.5 \\ \hline
MMP03       & 75.97\%   & 64.82\% & 69.96${\pm}$1.4 \\ \hline
CMP03b      & 75.47\%   & 63.82\% & 69.15${\pm}$1.3 \\ \hline
baseline    & 31.86\%   & 28.89\% & 30.30${\pm}$1.3 \\ \hline
\end{tabular}
\end{table}

\subsection{Описание корпуса}

Датасет состоит из 6 файлов - это файлы testa, testb, train для каждого из языков. testa использовался для проверки модели при разработке, testb - для итоговой оценки модели. Файлы содержат 4 столбца, разделенные пробелами. Первый элемент каждой строки - это само слово, второй - POS (part-of-speach) tag, третий - syntactic chunk tag, четвертый - named entity tag. Также интересной особенностью 2003 года стали предоставленные списки именованных сущностей и неразмеченные данные, которые предлагалось как-то использовать для улучшения системы. Английский корпус был представлен коллекцией новостных статей из Reuters Corpus. Аннотация была произведена в University of Antwerp. Немецкий корпус - коллекция статей от Frankfurter Rundschau. Пример содержимого файла train, а также сводная таблица (3) по размерам датасетов приведены ниже.

{\tt \small
\begin{verbatim}
WORD         POS  CHUNK NE
U.N.         NNP  I-NP  I-ORG 
official     NN   I-NP  O 
Ekeus        NNP  I-NP  I-PER 
heads        VBZ  I-VP  O 
for          IN   I-PP  O 
Baghdad      NNP  I-NP  I-LOC 
.            .    O     O 
\end{verbatim}
}


\begin{table}[ht]
\centering
\caption{Размеры датасетов}
\label{size}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{} & \textbf{Learning} & \textbf{Validating} & \textbf{Testing} \\ \hline
Articles  & 946               & 216                 & 231              \\ \hline
Sentences & 14987             & 3466                & 3684             \\ \hline
Tokens    & 203621            & 51362               & 46435            \\ \hline
LOC       & 7140              & 1837                & 1668             \\ \hline
MISC      & 3438              & 922                 & 702              \\ \hline
ORG       & 6321              & 1341                & 1661             \\ \hline
PER       & 6600              & 1842                & 1617             \\ \hline
\end{tabular}
\end{table}

\subsection{Итоги дорожки}

Большинство систем на английском языке показали результаты в районе 88 - 80 при baseline в 71. На немецком языке системы проявили себя хуже - максимум 72, большинство работ в районе 60-70, однако и baseline тут значительно ниже - 30. Рассмотрим трех участников, показавших лучшие результаты для английского языка:

\subsubsection{FIJZ03 - 88.76}

Первое место заняла модель команды FIJZ03, достигшая результата в 88.76 \cite{Florian:2003:NER:1119176.1119201}. Авторы модели использовали комбинацию четырех различных классификаторов - линейный классификатор, максимальной энтропии, основанное на трансформации обучение и скрытую Марковскую модель. Без газетиров и других дополнительных ресурсов они достигли результата в 91.6 на тренировочных данных, с использованием дополнительных данных сумели получить дополнительное уменьшение ошибки на 15 - 20 процентов. Также авторы отмечают, что устойчивый классификатор минимизации риска "выглядит особенно подходящим для обработки дополнительных источников признаков, и потому является хорошим кандидатом для комбинации классификаторов". Результаты работы данной модели приведены в таблицах 4 и 5.\\


Список рассматриваемых признаков:
\begin{itemize}
\setlength\itemsep{0em}
\item слова и их леммы в окне размеров в пять слов около текущего
\item POS тег текущего и окружающего слов
\item текстовые чанки в окне -1..1
\item префиксы и суффиксы длины до 4 букв текущего и окружающего слов
\item флаги, отражающие наличие заглавных букв (firstCap, 2digit and allCaps)
\item информация из газетира
\item результат работы двух других классификаторов, натренированных на более богатом датасете с большим числом категория
\end{itemize}

\begin{table}[ht]
\centering
\caption{FIJZ03 English Test}
\label{1place_eng}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{English test} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \hline
LOC                   & 90.59\%            & 91.73\%         & 91.15       \\ \hline
MISC                  & 83.46\%            & 77.64\%         & 80.44       \\ \hline
ORG                   & 85.93\%            & 83.44\%         & 84.67       \\ \hline
PER                   & 92.49\%            & 95.24\%         & 93.85       \\ \hline
overall               & 88.99\%            & 88.54\%         & 88.76       \\ \hline
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\caption{FIJZ03 German Test}
\label{1place_ger}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{German test} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \hline
LOC                  & 80.19\%            & 71.59\%         & 75.65       \\ \hline
MISC                 & 77.87\%            & 41.49\%         & 54.14       \\ \hline
ORG                  & 79.43\%            & 54.46\%         & 64.62       \\ \hline
PER                  & 91.93\%            & 75.31\%         & 82.80       \\ \hline
overall              & 83.87\%            & 63.71\%         & 72.41       \\ \hline
\end{tabular}
\end{table}

\subsubsection{CN03 - 88.31}

Авторы модели использовали подход, основанный на принципе максимума энтропии, причем использовали в качестве признаков не только локальный контекст, но также использовали и остальные вхождения этого слова для извлечения полезных признаков (т.н. глобальные признаки) \cite{Chieu:2003:NER:1119176.1119199}. Для этого они обработали датасет и создали несколько списков слов - Frequent Word List, Useful Unigrams, Useful Bigrams, Useful Word Suffixes, Useful Name Class Suffixes, Function Words, которые в дальнейшем использовались для выделения глобальных признаков. \\

К сожалению, в предоставленной авторами статье нет никакой информации по отбору признаков, только их перечисление, а название Useful, например, Useful Unigrams, говорит о том, что лист содержит 1-граммы, которые часто предшествуют определенному типу сущностей, а потому могут быть полезны при классификации. Однако в статье довольно подробно описаны листы и получаемые из них признаки, так что она может послужить основой для дальнейшего изучения возможностей по использованию глобальных признаков. Результаты работы данной модели приведены в таблицах 6 и 7.

\begin{table}[ht]
\centering
\caption{CN03 English Test}
\label{2place_eng}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{English test} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \hline
LOC                   & 90.88\%            & 91.37\%         & 91.12       \\ \hline
MISC                  & 80.15\%            & 78.21\%         & 79.16       \\ \hline
ORG                   & 83.82\%            & 84.83\%         & 84.32       \\ \hline
PER                   & 93.07\%            & 93.82\%         & 93.44       \\ \hline
Overall               & 88.12\%            & 88.51\%         & 88.31       \\ \hline
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\caption{CN03 German Test}
\label{2place_ger}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{German test} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \hline
LOC                  & 69.23\%            & 59.13\%         & 63.78       \\ \hline
MISC                 & 62.05\%            & 33.43\%         & 43.45       \\ \hline
ORG                  & 76.70\%            & 48.12\%         & 59.14       \\ \hline
PER                  & 88.82\%            & 75.15\%         & 81.41       \\ \hline
Overall              & 76.83\%            & 57.34\%         & 65.67       \\ \hline
\end{tabular}
\end{table}


\subsubsection{KSNM03 - 86.07}

Авторы рассматривают две модели - скрытую марковскую модель и conditional markov model, рассматривая в качестве базовых единиц не слова, а символы и n-граммы \cite{Klein:2003:NER:1119176.1119204}. При разработке первой модели использование контекста было минимально, а при разработке второй использовался подход максимальной энтропии, после чего добавили дополнительные признаки и объединили модели в CMM.
Результаты работы данной модели приведены в таблицах 8 и 9.

\begin{table}[ht]
\centering
\caption{KSNM03 English Test}
\label{3place_eng}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{English test} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \hline
LOC                   & 90.04              & 89.93           & 89.98       \\ \hline
MISC                  & 83.49              & 77.07           & 80.15       \\ \hline
ORG                   & 82.49              & 78.57           & 80.48       \\ \hline
PER                   & 86.66              & 95.18           & 90.72       \\ \hline
Overall               & 86.12              & 86.49           & 86.31       \\ \hline
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{KSNM03 German Test}
\label{3place_ger}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{German test} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \hline
LOC                  & 78.01              & 69.57           & 73.54       \\ \hline
MISC                 & 75.90              & 47.01           & 58.06       \\ \hline
ORG                  & 73.26              & 51.75           & 60.65       \\ \hline
PER                  & 87.68              & 79.83           & 83.57       \\ \hline
Overall              & 80.38              & 65.04           & 71.90       \\ \hline
\end{tabular}
\end{table}

\subsubsection{Итоги}

Подводя итоги, отметим, что в 2003 году часто использовались и хорошо себя проявили такие классификаторы, как HMM и максимальной энтропии. Кроме того, многие авторы отмечали тот факт, что категория MISC довольно сильно повлияла на снижение качества работы моделей, связывая это с обобщенностью данной категории.

\subsection{CRF и современные работы}
\subsubsection{CRF}

Рассмотрим статью Andrew McCallum and Wei Li, в которой они обращаются к CRF, индуцированию признаков и методу WebListing для создания лексиконов \cite{McCallum:2003:ERN:1119176.1119206}. Их система показала неплохой результат в 84.04 (F-мера), что доказывает применимость CRF в задачах выделения именованных сущностей.

\begin{table}[ht]
\centering
\caption{CRF English Test}
\label{crf_eng}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{English test} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \hline
LOC                   & 87.23\%            & 87.65\%         & 87.44       \\ \hline
MISC                  & 74.44\%            & 71.37\%         & 72.87       \\ \hline
ORG                   & 79.52\%            & 78.33\%         & 78.92       \\ \hline
PER                   & 91.05\%            & 89.98\%         & 90.51       \\ \hline
Overall               & 84.52\%            & 83.55\%         & 84.04       \\ \hline
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\caption{CRF German Test}
\label{crf_ger}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{German test} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \hline
LOC                  & 71.92\%            & 69.28\%         & 70.57       \\ \hline
MISC                 & 69.59\%            & 42.69\%         & 52.91       \\ \hline
ORG                  & 63.85\%            & 48.90\%         & 55.38       \\ \hline
PER                  & 90.04\%            & 74.14\%         & 81.32       \\ \hline
Overall              & 75.97\%            & 61.72\%         & 68.11       \\ \hline
\end{tabular}
\end{table}

\subsubsection{Современные работы}

В последние годы появилось довольно много статей, рассматривающих использование LSTM-CNNs, LSTM-CRF, LSTM-CNNs-CRF для датасета CoNLL2003. На данный момент один из наилучших результатов (State Of Art) был достигнут в 2016 году Xuezhe Ma и Eduard Hovy, используя BLSTM-CNNs-CRF, они смогли добиться результата в 91.21 (F-мера) без использования сторонних данных \cite{DBLP:journals/corr/MaH16}. В 2015 году была достигнута планка в 91.62 при помощи LSTM-CNNs и использовании двух наборов данных, полученных из публично доступных источников, авторы второй статьи также называют свой результат наилучшим \cite{DBLP:journals/corr/ChiuN15}.  \\

Схема BLSTM-CNNs-CRF:

\begin{enumerate}
\item Используя CNN, извлекают морфологическую информацию, кодируют ее в символьное представление.
\item Отправляют результат первого шага в BLSTM (отмечается важность dropout слоя).
\item Результат работы BLSTM отправляется CRF.
\end{enumerate}

Результатов для каждого из типов сущностей авторы не предоставили.