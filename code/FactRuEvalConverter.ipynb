{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from corpus import ConllCorpusReaderX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def prepare(dataset):\n",
    "    factrueval_dev_tokens = dict()\n",
    "    factrueval_dev_tokens_list = []\n",
    "    factrueval_dev_spans = dict()\n",
    "    factrueval_dev_objects = dict()\n",
    "    for file in os.listdir('./factrueval2016_dataset/'+ dataset + '/'):\n",
    "        if file.endswith('tokens'):\n",
    "            with open('./factrueval2016_dataset/' + dataset + '/' + file, 'r+', encoding='utf-8') as file_obj:\n",
    "                lines = file_obj.readlines()\n",
    "                tokens = [line.rstrip().split() for line in lines if line.rstrip().split() != []]\n",
    "                for token in tokens:\n",
    "                    factrueval_dev_tokens[int(token[0])] = token[1:]\n",
    "                tokens = [line.rstrip().split() for line in lines]\n",
    "                for token in tokens:\n",
    "                    factrueval_dev_tokens_list.append(token)\n",
    "\n",
    "        if file.endswith('spans'):\n",
    "            with open('./factrueval2016_dataset/' + dataset + '/' + file, 'r+', encoding='utf-8') as file_obj:\n",
    "                spans = [line.rstrip().split() for line in file_obj.readlines() if line.rstrip().split() != []]\n",
    "                for span in spans:\n",
    "                    factrueval_dev_spans[span[0]] = span[1:]\n",
    "\n",
    "        if file.endswith('objects'):\n",
    "            with open('./factrueval2016_dataset/' + dataset + '/' + file, 'r+', encoding='utf-8') as file_obj:\n",
    "                objects = [line.rstrip().split('#')[0].split() for line in file_obj.readlines() if line.rstrip().split() != []]\n",
    "                for obj in objects:\n",
    "                    factrueval_dev_objects[obj[0]] = obj[1:]\n",
    "\n",
    "    all_ne = []\n",
    "    for key, value in factrueval_dev_objects.items():\n",
    "        spans = value[1:]\n",
    "        ne = value[0]\n",
    "        all_tokens = []\n",
    "        for span in spans:\n",
    "            span_obj = factrueval_dev_spans[span]\n",
    "            token = int(span_obj[3])\n",
    "            num_of_tokens = int(span_obj[4])\n",
    "            for i in range(num_of_tokens):\n",
    "                all_tokens.append(token + i)\n",
    "        all_ne.append([ne, sorted(all_tokens)])\n",
    "\n",
    "    for ne_tokens in all_ne:\n",
    "        ne = ne_tokens[0]\n",
    "        token = ne_tokens[1]\n",
    "        for i in range(len(token)):\n",
    "            if token[i] in factrueval_dev_tokens.keys():\n",
    "                if len(token) == 1:\n",
    "                    factrueval_dev_tokens[token[i]].append(\"S-\" + ne)\n",
    "                elif (i == 0 and token[i + 1] - token[i] > 1) or (i == len(token) - 1 and token[i] - token[i - 1] > 1) or (token[i] - token[i - 1] > 1 and token[i + 1] - token[i] > 1):\n",
    "                    factrueval_dev_tokens[token[i]].append(\"S-\" + ne)\n",
    "                elif (i == 0  and token[i + 1] - token[i] == 1) or (i != len(token) - 1 and token[i] - token[i - 1] > 1 and token[i + 1] - token[i] == 1):\n",
    "                    factrueval_dev_tokens[token[i]].append(\"B-\" + ne)\n",
    "                elif (i == len(token) - 1 and token[i] - token[i - 1] == 1) or (i != 0 and token[i] - token[i - 1] == 1 and token[i + 1] - token[i] > 1):\n",
    "                    factrueval_dev_tokens[token[i]].append(\"E-\" + ne)\n",
    "                else: \n",
    "                    factrueval_dev_tokens[token[i]].append(\"I-\" + ne)\n",
    "\n",
    "    for i in range(len(factrueval_dev_tokens_list)):\n",
    "        if factrueval_dev_tokens_list[i] == []:\n",
    "            continue\n",
    "        number_of_token = factrueval_dev_tokens_list[i][0]\n",
    "        if int(number_of_token) in factrueval_dev_tokens.keys() and len(factrueval_dev_tokens[int(number_of_token)]) >= 4:\n",
    "            ne = factrueval_dev_tokens[int(number_of_token)][3]\n",
    "            factrueval_dev_tokens_list[i].append(ne)\n",
    "        else:\n",
    "            factrueval_dev_tokens_list[i].append(\"O\")\n",
    "\n",
    "    final = []\n",
    "    for el in factrueval_dev_tokens_list:\n",
    "        if el == []:\n",
    "            final.append(el)\n",
    "        else:\n",
    "            final.append([el[3], el[1], el[2], el[4]])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devset = prepare('devset')\n",
    "with open('./factrueval2016_dataset/devset.txt', 'w+', encoding='utf-8') as file:\n",
    "    file.write(\"-DOCSTART- O\\n\")\n",
    "    for line in devset:\n",
    "        if line == []:\n",
    "            file.write(\"\\n\")\n",
    "        else:\n",
    "            file.write(\"{} {} {} {}\\n\".format(*line))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset = prepare('testset')\n",
    "with open('./factrueval2016_dataset/testset.txt', 'w+', encoding='utf-8') as file:\n",
    "    file.write(\"-DOCSTART- O\\n\")\n",
    "    for line in testset:\n",
    "        if line == []:\n",
    "            file.write(\"\\n\")\n",
    "        else:\n",
    "            file.write(\"{} {} {} {}\\n\".format(*line))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factrueval_devset = ConllCorpusReaderX('./factrueval2016_dataset/', \n",
    "                              fileids='devset.txt', \n",
    "                              columntypes=['words', 'offset', 'len', 'ne'])\n",
    "\n",
    "factrueval_testset = ConllCorpusReaderX('./factrueval2016_dataset/', \n",
    "                              fileids='testset.txt', \n",
    "                              columntypes=['words', 'offset', 'len', 'ne'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Демонстрация работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('В', 'O', '0', '1'), ('понедельник', 'O', '2', '11'), ('28', 'O', '14', '2'), ('июня', 'O', '17', '4'), ('у', 'O', '22', '1'), ('здания', 'O', '24', '6'), ('мэрии', 'B-Org', '31', '5')]\n"
     ]
    }
   ],
   "source": [
    "print(factrueval_devset.get_tags(tags=['words', 'ne', 'offset', 'len'])[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['В', 'понедельник', '28', 'июня', 'у', 'здания', ...]\n",
      "30940\n"
     ]
    }
   ],
   "source": [
    "print(factrueval_devset.words())\n",
    "print(len(factrueval_devset.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('В', 'O'), ('понедельник', 'O'), ('28', 'O'), ...]\n"
     ]
    }
   ],
   "source": [
    "print(factrueval_devset.get_ne())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from generator import Generator\n",
    "\n",
    "words = [[el] for el in factrueval_devset.words()[:4000]]\n",
    "gen = Generator(column_types=['word'], context_len=2)\n",
    "X = gen.generate(words, path='./factrueval_devset.npy')\n",
    "y = np.array([el[1] for el in factrueval_devset.get_ne()[:4000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X[:3000], y[:3000])\n",
    "y_pred = clf.predict(X[3000:4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5340314136125655\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "total_a = 0\n",
    "total_b = 0\n",
    "for a, b in zip(y_pred, y[3000:4000]):\n",
    "    if a != 'O':\n",
    "        total_a += 1\n",
    "    if b != 'O':\n",
    "        total_b += 1    \n",
    "    if a != 'O' and a == b:\n",
    "        right += 1\n",
    "accuracy = right/total_a\n",
    "recall = right/total_b\n",
    "f = 2 * accuracy * recall /(accuracy + recall)\n",
    "print(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
