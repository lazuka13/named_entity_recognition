{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "\n",
    "result = []\n",
    "\n",
    "for file in os.listdir('./bsnlp_dataset/eu_annot/'):\n",
    "    number = int(file.split('.')[0])\n",
    "    with open('./bsnlp_dataset/eu_annot/' + file, encoding='utf-8') as annot_file:\n",
    "        annot = annot_file.readlines()[1:]\n",
    "        annot = [simple_word_tokenize(el.strip()) for el in annot]\n",
    "        annot = [el[:int((len(el) - 2)/2)] + [el[-2]] for el in annot]\n",
    "    with open('./bsnlp_dataset/eu/file_' + str(number) + \"_ru.txt\", encoding='utf-8') as text_file:\n",
    "        text = text_file.readlines()[4:]\n",
    "        text = [simple_word_tokenize(line.strip()) for line in text]\n",
    "        text = [el for el in text if el != []]\n",
    "        total_words = []\n",
    "        for el in text:\n",
    "            total_words += el\n",
    "            total_words += ' '\n",
    "        total_words = [el for el in total_words]\n",
    "        total_ne = ['O' for el in total_words]\n",
    "\n",
    "    for ne in annot:\n",
    "        words_count = len(ne) - 1\n",
    "        for i in range(len(total_words) - words_count - 1):\n",
    "            if ne[:-1] == [el.lower() for el in total_words[i: i + words_count]]:\n",
    "                if words_count == 1:\n",
    "                    total_ne[i] = 'S-' + ne[-1]\n",
    "                else:\n",
    "                    total_ne[i] = 'B-' + ne[-1]\n",
    "                    total_ne[i + words_count - 1] = 'E-' + ne[-1]\n",
    "                    for j in range(i + 1, i + words_count - 1):\n",
    "                        total_ne[j] = 'I-' + ne[-1]\n",
    "\n",
    "    for word, ne in zip(total_words, total_ne):\n",
    "        if word != \" \":\n",
    "            result.append(word + ' ' +  ne + '\\n')\n",
    "        else:\n",
    "            result.append('\\n')\n",
    "            \n",
    "with open('./bsnlp_dataset/ec.txt', 'w+', encoding='utf-8') as file:\n",
    "    file.write(\"-DOCSTART- O\\n\")\n",
    "    for line in result:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for file in os.listdir('./bsnlp_dataset/trump_annot/'):\n",
    "    number = int(file.split('.')[0])\n",
    "    with open('./bsnlp_dataset/trump_annot/' + file, encoding='utf-8') as annot_file:\n",
    "        annot = annot_file.readlines()[1:]\n",
    "        annot = [simple_word_tokenize(el.strip()) for el in annot]\n",
    "        annot = [el[:int((len(el) - 2)/2)] + [el[-2]] for el in annot]\n",
    "    with open('./bsnlp_dataset/trump/file_' + str(number) + \".txt\", encoding='utf-8') as text_file:\n",
    "        text = text_file.readlines()[4:]\n",
    "        text = [simple_word_tokenize(line.strip()) for line in text]\n",
    "        text = [el for el in text if el != []]\n",
    "        total_words = []\n",
    "        for el in text:\n",
    "            total_words += el\n",
    "            total_words += ' '\n",
    "        total_words = [el for el in total_words]\n",
    "        total_ne = ['O' for el in total_words]\n",
    "\n",
    "    for ne in annot:\n",
    "        words_count = len(ne) - 1\n",
    "        for i in range(len(total_words) - words_count - 1):\n",
    "            if ne[:-1] == [el.lower() for el in total_words[i: i + words_count]]:\n",
    "                if words_count == 1:\n",
    "                    total_ne[i] = 'S-' + ne[-1]\n",
    "                else:\n",
    "                    total_ne[i] = 'B-' + ne[-1]\n",
    "                    total_ne[i + words_count - 1] = 'E-' + ne[-1]\n",
    "                    for j in range(i + 1, i + words_count - 1):\n",
    "                        total_ne[j] = 'I-' + ne[-1]\n",
    "\n",
    "    for word, ne in zip(total_words, total_ne):\n",
    "        if word != \" \":\n",
    "            result.append(word + ' ' +  ne + '\\n')\n",
    "        else:\n",
    "            result.append('\\n')\n",
    "            \n",
    "with open('./bsnlp_dataset/trump.txt', 'w+', encoding='utf-8') as file:\n",
    "    file.write(\"-DOCSTART- O\\n\")\n",
    "    for line in result:\n",
    "        file.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
