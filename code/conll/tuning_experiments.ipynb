{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import datetime as dt\n",
    "\n",
    "from generator import Generator\n",
    "from corpus import ConllCorpusReaderX\n",
    "from estimator import Estimator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TRAINSET_PATH = \"./conll_trainset.npz\"\n",
    "TESTSETA_PATH = \"./conll_testseta.npz\"\n",
    "TESTSETB_PATH = \"./conll_testsetb.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conll_trainset = ConllCorpusReaderX('./conll2003_dataset', \n",
    "                              fileids='eng.train.txt', \n",
    "                              columntypes=('words', 'pos', 'chunk', 'ne'))\n",
    "\n",
    "conll_testseta = ConllCorpusReaderX('./conll2003_dataset', \n",
    "                              fileids='eng.testa.dev.txt', \n",
    "                              columntypes=('words', 'pos', 'chunk', 'ne'))\n",
    "\n",
    "conll_testsetb = ConllCorpusReaderX('./conll2003_dataset', \n",
    "                              fileids='eng.testb.test.txt', \n",
    "                              columntypes=('words', 'pos', 'chunk', 'ne'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = Generator(column_types=['WORD', 'POS', 'CHUNK'], context_len=2, language='en')\n",
    "\n",
    "Y_train = [el[1] for el in conll_trainset.get_ne()]\n",
    "Y_testa = [el[1] for el in conll_testseta.get_ne()] \n",
    "Y_testb = [el[1] for el in conll_testsetb.get_ne()] \n",
    "\n",
    "X_train = gen.fit_transform(conll_trainset.get_tags(tags=['words', 'pos', 'chunk']), Y_train, path=TRAINSET_PATH)\n",
    "X_testa = gen.transform(conll_testseta.get_tags(tags=['words', 'pos', 'chunk']), path=TESTSETA_PATH)\n",
    "X_testb = gen.transform(conll_testsetb.get_tags(tags=['words', 'pos', 'chunk']), path=TESTSETB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Label2IdX:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "        self.index = 0\n",
    "        \n",
    "    def get(self, label):\n",
    "        if label in self.data:\n",
    "            return self.data[label]\n",
    "        else:\n",
    "            self.data[label] = self.index\n",
    "            self.index += 1\n",
    "            return self.data[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_parameters(clf_class, tuned_parameters_grid):\n",
    "    \n",
    "    best_total_F = 0\n",
    "    best_parameters = None\n",
    "    \n",
    "    # создаем хранитель индексов\n",
    "    label2idx = Label2IdX()\n",
    "    \n",
    "    # преобразуем набор ответов\n",
    "    Y_testb_sent = []\n",
    "    \n",
    "    index = 0\n",
    "    for sent in conll_testsetb.sents():\n",
    "        length = len(sent)\n",
    "        Y_testb_sent.append([label2idx.get(el) for el in Y_testb[index:index+length]])\n",
    "        index += length\n",
    "    \n",
    "    # тестируем\n",
    "    for parameters in ParameterGrid(tuned_parameters_grid):\n",
    "        clf = clf_class()\n",
    "        clf.set_params(**parameters)\n",
    "    \n",
    "        clf.fit(X_train, Y_train)\n",
    "        Y_predb = clf.predict(X_testb)\n",
    "\n",
    "        # преобразуем данные для оценки\n",
    "        Y_predb_sent = []\n",
    "        \n",
    "        index = 0\n",
    "        for sent in conll_testsetb.sents():\n",
    "            length = len(sent)\n",
    "            Y_predb_sent.append([label2idx.get(el) for el in Y_predb[index:index+length]])\n",
    "            index += length\n",
    "\n",
    "        F_arr = []\n",
    "        weight_arr = []\n",
    "\n",
    "        labels = [\"PER\", \"ORG\", \"LOC\", \"MISC\"]\n",
    "        for label in labels:\n",
    "            estimator = Estimator(Y_predb_sent, Y_testb_sent, label, labels, label2idx)\n",
    "            F = estimator.compute_proper_f1()\n",
    "            F_arr.append(F)\n",
    "            weight = estimator.get_weight()\n",
    "            weight_arr.append(weight)\n",
    "\n",
    "        total_F = sum([F * weight for F, weight in zip(F_arr, weight_arr)]) / sum(weight_arr)\n",
    "        \n",
    "        if total_F > best_total_F:\n",
    "            best_total_F = total_F\n",
    "            best_parameters = parameters\n",
    "        \n",
    "    print(\"BEST RESULT: {}\".format(best_total_F))\n",
    "    print(\"WITH PARAMETERS:\")\n",
    "    print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-19 21:59:14.839948\n",
      "BEST RESULT: 0.7202792475799831\n",
      "WITH PARAMETERS:\n",
      "{'C': 1.4, 'max_iter': 100, 'n_jobs': 4, 'tol': 0.0001}\n",
      "2017-12-19 23:18:27.423938\n"
     ]
    }
   ],
   "source": [
    "print(dt.datetime.now())\n",
    "\n",
    "tuned_parameters = [\n",
    "    {\n",
    "        \"C\": [1.4, 1.2, 1.0],\n",
    "        \"max_iter\": [100, 200, 500],\n",
    "        \"tol\": [5e-5, 1e-4, 1e-3],\n",
    "        \"n_jobs\": [4]\n",
    "    }\n",
    "]\n",
    "\n",
    "get_best_parameters(LogisticRegression, tuned_parameters)\n",
    "print(dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-19 23:18:27.484482\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter min_sample_leaf for estimator RandomForestClassifier. Check the list of available parameters with `estimator.get_params().keys()`.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1e8264118a1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m ]\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mget_best_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-607513fcfdab>\u001b[0m in \u001b[0;36mget_best_parameters\u001b[1;34m(clf_class, tuned_parameters_grid)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuned_parameters_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\n_ame\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    281\u001b[0m                                      \u001b[1;34m'Check the list of available parameters '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                                      \u001b[1;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                                      (key, self.__class__.__name__))\n\u001b[0m\u001b[0;32m    284\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter min_sample_leaf for estimator RandomForestClassifier. Check the list of available parameters with `estimator.get_params().keys()`."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(dt.datetime.now())\n",
    "\n",
    "tuned_parameters = [\n",
    "    {\n",
    "        \"n_estimators\": [100, 300, 800, 1000],\n",
    "        \"min_sample_leaf\": [5, 10, 15],\n",
    "        \"max_features\": [\"sqrt\", \"log2\", 50.0, 20.0, 80.0],\n",
    "        \"n_jobs\": [4]\n",
    "    }\n",
    "]\n",
    "\n",
    "get_best_parameters(RandomForestClassifier, tuned_parameters)\n",
    "print(dt.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
